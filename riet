#!/usr/bin/env python3

import itertools as it, operator as op, functools as ft
import os, sys, logging, re, time, math, subprocess
import datetime as dt, collections as cs, pathlib as pl
import contextlib, tempfile, stat, base64, hashlib, json

import pytz
# As-needed deps: docutils, icalendar


class LogMessage:
	def __init__(self, fmt, a, k): self.fmt, self.a, self.k = fmt, a, k
	def __str__(self): return self.fmt.format(*self.a, **self.k) if self.a or self.k else self.fmt

class LogStyleAdapter(logging.LoggerAdapter):
	def __init__(self, logger, extra=None):
		super(LogStyleAdapter, self).__init__(logger, extra or {})
	def log(self, level, msg, *args, **kws):
		if not self.isEnabledFor(level): return
		log_kws = {} if 'exc_info' not in kws else dict(exc_info=kws.pop('exc_info'))
		msg, kws = self.process(msg, kws)
		self.logger._log(level, LogMessage(msg, args, kws), (), **log_kws)

get_logger = lambda name: LogStyleAdapter(logging.getLogger(name))
log = get_logger('main')

class adict(dict):
	def __init__(self, *args, **kwargs):
		super().__init__(*args, **kwargs)
		self.__dict__ = self

@contextlib.contextmanager
def safe_replacement(path, *open_args, mode=None, **open_kws):
	path = str(path)
	if mode is None:
		try: mode = stat.S_IMODE(os.lstat(path).st_mode)
		except OSError: pass
	open_kws.update( delete=False,
		dir=os.path.dirname(path), prefix=os.path.basename(path)+'.' )
	if not open_args: open_kws['mode'] = 'w'
	with tempfile.NamedTemporaryFile(*open_args, **open_kws) as tmp:
		try:
			if mode is not None: os.fchmod(tmp.fileno(), mode)
			yield tmp
			if not tmp.closed: tmp.flush()
			os.rename(tmp.name, path)
		finally:
			try: os.unlink(tmp.name)
			except OSError: pass

str_hash = lambda p: base64.urlsafe_b64encode(
	hashlib.blake2s(str(p).encode(), key=b'riet.path_hash').digest() ).decode()[:12]

def tuple_hash(data):
	src = list()
	for v in data:
		if v is None: src.append('\ue003')
		elif isinstance(v, (int, str, dt.tzinfo)): src.append(str(v))
		elif isinstance(v, tuple): src.append(tuple_hash(v))
		elif isinstance(v, dt.datetime):
			src.append(conv_ts_utc(v).strftime('%Y-%m-%dT%H:%M:%S.%f'))
		elif isinstance(v, dt.timedelta): src.append('\ue002{v.total_seconds()}')
		elif isinstance(v, set): src.append(tuple_hash(sorted(v)))
		else: raise ValueError(type(v), v)
	return str_hash('\ue000'.join(
		'\ue001{}\ue001'.format(v.replace('\ue001', '\ue001'*2)) for v in src ))

bb = lambda v: v.encode() if isinstance(v, str) else v
ss = lambda v: v.decode() if isinstance(v, bytes) else v



### Persistent state tracking

class PersistentStateError(Exception): pass

class PersistentState(cs.UserDict):

	version = 1

	def __setitem__(self, k, v):
		return super().__setitem__(k, (time.time(), v))
	def __getitem__(self, k):
		v = super().__getitem__(k)[1]
		self[k] = v # update ts
		return v

	def load(self, dump):
		if not dump or not dump.get('version'):
			self.ts_init, self.data = time.time(), dump
		else:
			if dump['version'] != self.version: # only this one recognized so far
				raise PersistentStateError(
					f'Unrecognized state-dump version: {dump["version"]}' )
			self.ts_init, self.data = dump['ts_init'], dump['data']

	def dump(self):
		return dict(version=self.version, ts_init=self.ts_init, data=self.data)

	def cleanup(self, ts_min=None, timeout=2*365*24*3600):
		if ts_min is None: ts_min = time.time() - timeout
		for k, v in list(self.data.items()):
			if v[0] < ts_min: self.data.pop(k)



### D-Bus helpers

class SDBus:

	_lib_info, _lib_info_t = None, cs.namedtuple(
		'sd_bus_lib', 'ct lib bus_t bus err_t err msg_t msg' )
	@classmethod
	def _get_lib_info(cls):
		if not cls._lib_info:
			import ctypes as ct
			lib = ct.CDLL('libsystemd.so')
			class sd_bus(ct.Structure): pass
			class sd_bus_error(ct.Structure):
				_fields_ = [('name', ct.c_char_p), ('message', ct.c_char_p), ('need_free', ct.c_int)]
			class sd_bus_msg(ct.Structure): pass
			cls._lib_info = cls._lib_info_t( ct, lib,
				sd_bus, ct.POINTER(sd_bus)(),
				sd_bus_error, sd_bus_error(),
				sd_bus_msg, ct.POINTER(sd_bus_msg)() )
		return cls._lib_info

	def _run(self, lib, call, *args, sig=None, check=True):
		func = getattr(lib, call)
		if sig: func.argtypes = sig
		res = func(*args)
		if check and res < 0: raise OSError(-res, os.strerror(-res))
		return res

	def call( self,
			dst, path=None, iface=None, method=None, sig='', args=None,
			reply='', system=False, _call='sd_bus_call_method' ):
		if not method: dst, method = dst.rsplit('.', 1)
		if not path: path = '/' + dst.replace('.', '/')
		if not iface: iface = dst

		ct, lib, sd_bus, bus, sd_bus_error, err, sd_bus_msg, msg = self._get_lib_info()
		args, args_sig = args or [(), ()]
		if reply: # one value only
			reply_sig = ss(reply)
			reply_t = dict(i=ct.c_int32, u=ct.c_uint32, s=ct.c_char_p)[reply_sig]
			reply_sig, reply = bb(reply_sig), reply_t()
		else: reply_sig = None

		bus_name = 'user' if not system else 'system'
		self._run( lib, f'sd_bus_open_{bus_name}',
			ct.byref(bus), sig=[ct.POINTER(ct.POINTER(sd_bus))] )

		try:
			self._run( lib, _call, bus,
				bb(dst), bb(path), bb(iface), bb(method),
				ct.byref(err), ct.byref(msg), bb(sig), *args,
				sig=[
					ct.POINTER(sd_bus),
					ct.c_char_p, ct.c_char_p, ct.c_char_p, ct.c_char_p,
					ct.POINTER(sd_bus_error),
					ct.POINTER(ct.POINTER(sd_bus_msg)), ct.c_char_p, *args_sig ] )
			if reply_sig:
				n = self._run(
					lib, 'sd_bus_message_read', msg, reply_sig, ct.byref(reply),
					sig=[ct.POINTER(sd_bus_msg), ct.c_char_p, ct.POINTER(reply_t)] )
				if n <= 0: raise ValueError(n)
		finally: self._run(lib, 'sd_bus_flush_close_unref', bus, check=False)
		if reply: return reply.value

	def get(self, dst, path=None, iface=None, name=None, sig='s', system=False):
		return self.call( dst, path, iface, name, sig=sig,
			reply=sig, system=system, _call='sd_bus_get_property' )


def get_local_tz():
	# Cached on first access to avoid dbus call on import
	if get_local_tz.cache: return get_local_tz.cache

	tz = os.environ.get('TZ', '').strip()
	if tz:
		get_local_tz.cache = pytz.timezone(tz)
		return get_local_tz.cache

	tz = SDBus().get('org.freedesktop.timedate1.Timezone', system=True)
	get_local_tz.cache = pytz.timezone(tz.decode())
	return get_local_tz.cache
get_local_tz.cache = None


def get_dbus_notify_func(**defaults):
	kws, defaults = defaults, dict(
		app='', replaces_id=0, icon='',
		summary='', body='', actions=None, hints=None, timeout=-1 )
	for k in defaults:
		if k in kws: defaults[k] = kws.pop(k)
	assert not kws, kws

	import ctypes as ct
	sdbus = SDBus()

	def encode_array(v):
		if not v: sig, args = [ct.c_void_p], [None]
		elif isinstance(v, list): # list of str
			sig, args = [ct.c_int, [ct.c_char_p] * len(v)], [len(v), *map(bb, v)]
		elif isinstance(v, dict): # str keys, int/str values
			sig, args = [ct.c_int], [len(v)]
			for ak, av in v.items():
				sig.extend([ct.c_char_p, ct.c_char_p]) # key, type
				args.append(bb(ak))
				if isinstance(av, (str, bytes)):
					av_sig, av_args = [ct.c_char_p], [b's', bb(av)]
				elif isinstance(av, int): av_sig, av_args = [ct.c_int32], [b'i', av]
				else: av_sig, av_args = av
				args.extend(av_args)
				sig.extend(av_sig)
		else: raise ValueError(v)
		return sig, args

	def notify_func(
			summary=None, body=None, app=None, icon=None,
			replaces_id=None, actions=None, hints=None, timeout=None ):
		args, kws, sig_arrays = list(), locals(), list()
		for k, default in defaults.items():
			v = kws.get(k)
			if v is None: v = default
			if k in ['actions', 'hints']:
				arr_sig, arr_args = encode_array(v)
				sig_arrays.extend(arr_sig)
				args.extend(arr_args)
			else: args.append(bb(v))
		args = args, [ ct.c_char_p, ct.c_uint32, ct.c_char_p,
			ct.c_char_p, ct.c_char_p, *sig_arrays, ct.c_int32 ]
		return sdbus.call(
			'org.freedesktop.Notifications.Notify',
			sig='susssasa{sv}i', args=args, reply='u' )
	return notify_func



### Date/time processing helpers

class TSParseError(Exception): pass
class TSOverflow(Exception): pass

# Common timezone abbrevs which pytz refuses to handle
# Use make-tza-map.py script to produce these mappings from timezonedb.com/download csv
tza_map = dict(line.split('=', 1) for line in '''
	EMT=Pacific/Easter PPT=America/Los_Angeles YST=America/Anchorage JST=Asia/Tokyo
	RMT=Europe/Rome PKT=Asia/Karachi AMT=Europe/Amsterdam EST=America/New_York
	QMT=America/Guayaquil PDDT=America/Inuvik WEST=Europe/Paris JDT=Asia/Tokyo
	NDDT=America/St_Johns AWDT=Australia/Perth CST=America/Chicago KMT=Europe/Kiev
	SDMT=America/Santo_Domingo AEDT=Australia/Sydney CDT=America/Chicago
	EDDT=America/Iqaluit AWST=Australia/Perth PKST=Asia/Karachi CET=Europe/Berlin
	AKDT=America/Anchorage HDT=Pacific/Honolulu CEST=Europe/Berlin LST=Europe/Riga
	CWT=America/Chicago CPT=America/Chicago IMT=Europe/Istanbul SST=Pacific/Midway
	MST=America/Phoenix EET=Europe/Sofia EEST=Europe/Sofia PLMT=Asia/Ho_Chi_Minh
	PST=America/Los_Angeles PDT=America/Los_Angeles HKT=Asia/Hong_Kong
	HST=Pacific/Honolulu SJMT=America/Costa_Rica HMT=Europe/Helsinki KST=Asia/Seoul
	GMT=Europe/London WEMT=Europe/Paris AEST=Australia/Sydney IST=Asia/Jerusalem
	JMT=Asia/Jerusalem SET=Europe/Stockholm IDT=Asia/Jerusalem WAT=Africa/Lagos
	CEMT=Europe/Berlin NZMT=Pacific/Auckland FMT=Atlantic/Madeira WIT=Asia/Jayapura
	MDT=America/Phoenix WAST=Africa/Ndjamena EPT=America/New_York WMT=Europe/Warsaw
	AKST=America/Anchorage CMT=America/Argentina/Buenos_Aires TMT=Asia/Tehran
	BST=Europe/London MSD=Europe/Moscow AHDT=America/Anchorage WET=Europe/Paris
	MSK=Europe/Moscow MMT=Europe/Moscow PWT=America/Los_Angeles MDST=Europe/Moscow
	TBMT=Asia/Tbilisi PPMT=America/Port-au-Prince FFMT=America/Martinique
	KDT=Asia/Seoul NZDT=Pacific/Auckland EWT=America/New_York HKST=Asia/Hong_Kong
	SAST=Africa/Johannesburg ACDT=Australia/Adelaide ACST=Australia/Adelaide
	NZST=Pacific/Auckland EDT=America/New_York IDDT=Asia/Jerusalem
	DMT=Europe/Dublin AHST=America/Anchorage'''.split())

IntervalFilter = cs.namedtuple('interval_filter', 'mo_days weekdays time tz')
IntervalDelta = cs.namedtuple('interval_delta', 'y mo w d h m s')

weekday_names = 'mon tue wed thu fri sat sun'.title().split()
delta_1s, delta_1d = dt.timedelta(seconds=1), dt.timedelta(days=1)

_short_ts_days = dict(
	y=365.25, yr=365.25, year=365.25,
	mo=30.5, month=30.5, w=7, week=7, d=1, day=1 )
_short_ts_s = dict(
	h=3600, hr=3600, hour=3600,
	m=60, min=60, minute=60,
	s=1, sec=1, second=1 )
def _short_ts_re():
	sub_sort = lambda d: sorted(
		d.items(), key=lambda kv: (kv[1], len(kv[0])), reverse=True )
	ts_re = ['^'] + [
		r'(?P<{0}>\d*{0}\s*)?'.format(k)
		for k, v in it.chain.from_iterable(
			map(sub_sort, [_short_ts_days, _short_ts_s]) ) ] + ['$']
	return re.compile(''.join(ts_re), re.I | re.U)
_short_ts_re = _short_ts_re()

_filter_weekdays = list(map(str.split,
	[ 'mon monday', 'tu tue tuesday tues', 'wed wednesday',
		'th thu thursday thur thurs', 'fri friday', 'sat saturday', 'sun sunday' ] ))
_filter_weekdays_re = '(?:{})'.format(
	'|'.join('|'.join(wd) for wd in _filter_weekdays) )

def _delta_keys():
	ks = dict()
	for delta_k in IntervalDelta._fields:
		for vs in _short_ts_days, _short_ts_s:
			if delta_k not in vs: continue
			v_chk = vs[delta_k]
			for k, v in vs.items():
				if v == v_chk: ks[k] = delta_k
			break
		else: raise TSParseError(delta_k)
	return ks
_delta_keys = _delta_keys()
_delta_keys_dt = dict(
	y=(1, 'year'), mo=(1, 'month'), w=dt.timedelta(weeks=1), d=dt.timedelta(days=1),
	h=dt.timedelta(hours=1), m=dt.timedelta(minutes=1), s=dt.timedelta(seconds=1) )

_parse_int = lambda v: int(''.join(c for c in v if c.isdigit()) or 1)

def conv_ts_utc(ts):
	'Interpret any naive datetime as local-tz and convert to UTC.'
	if ts is None: return
	if isinstance(ts, (int, float)): ts = dt.datetime.fromtimestamp(ts)
	if not ts.tzinfo: ts = get_local_tz().localize(ts, is_dst=None)
	return ts.astimezone(pytz.utc)

def conv_ts_local(ts):
	'Convert datetime to local timezone for human output.'
	if not ts: return
	return ts.astimezone(get_local_tz())

def parse_delta_spec(ts_str):
	m = _short_ts_re.search(ts_str)
	if not m or not any(m.groups()): raise TSParseError(ts_str)
	delta = dict.fromkeys(IntervalDelta._fields, 0)
	for k, delta_k in _delta_keys.items():
		try: n = _parse_int(m.group(k)) if m.group(k) else 0
		except IndexError: n = 0
		delta[delta_k] += n
	for delta_k, n in delta.items():
		v = _delta_keys_dt[delta_k]
		if isinstance(v, dt.timedelta): v *= n
		else: v = v[0]*n, v[1]
		delta[delta_k] = v
	return IntervalDelta(**delta)

def parse_duration(ts_str):
	m = _short_ts_re.search(ts_str)
	if not m or not any(m.groups()): raise TSParseError(ts_str)
	delta = list()
	for units in _short_ts_days, _short_ts_s:
		val = 0
		for k, v in units.items():
			try:
				if not m.group(k): continue
				n = _parse_int(m.group(k))
			except IndexError: continue
			val += n * v
		delta.append(val)
	return dt.timedelta(*delta)

def parse_ts_or_interval(ts_str, multiple=False):
	m = re.search(r'(?i)^every\s+(.*)', ts_str)
	ts = ( parse_ts(ts_str, multiple=multiple)
		if not m else parse_ts_interval(m.group(1)) )
	if multiple and not isinstance(ts, list): ts = [ts]
	return ts

def parse_ts(ts_str, in_future=True, multiple=False):
	assert isinstance(ts_str, str), [type(ts_str), repr(ts_str)]
	ts = tz = None
	m = re.search(r'(.*)?\s+\[([^\]]+)\]\s*$', ts_str)
	if m:
		ts_str, tz = m.groups()
		tz = tz.strip()
		tz = pytz.timezone(tza_map.get(tz, tz))
	if not ts:
		match = re.search( # common BE format
			r'^(?P<date>(?:\d{2}|(?P<Y>\d{4}))-\d{2}-\d{2})'
			r'(?:[ T](?P<time>\d{2}(?::\d{2}(?::\d{2})?)?)?)?$', ts_str )
		if match:
			tpl = 'y' if not match.group('Y') else 'Y'
			tpl, ts_str = '%{}-%m-%d'.format(tpl), match.group('date')
			if match.group('time'):
				tpl_time = ['%H', '%M', '%S']
				ts_str_time = match.group('time').split(':')
				ts_str += ' ' + ':'.join(ts_str_time)
				tpl += ' ' + ':'.join(tpl_time[:len(ts_str_time)])
			try: ts = dt.datetime.strptime(ts_str, tpl)
			except ValueError: pass
	if not ts:
		# coreutils' "date" parses virtually everything, but is more expensive to use
		ts_ext, ts_list = [ts_str], list()
		if in_future: ts_now_sec, ts_now_date = time.time(), dt.date.today()
		while True:
			ts_str_ext = ' '.join(ts_ext)
			res = subprocess.run( ['date', '+%s', '-d', ts_str_ext],
					stdout=subprocess.PIPE, stderr=subprocess.DEVNULL )
			if not res.returncode:
				val = int(res.stdout.strip())
				# Try to add +1 day to simple timestamps like 3:00 if they're in the past
				# Whitelisted cases: 1:00, 4am, 5am GMT, 3:30 UTC-4
				if in_future and 0 < ts_now_sec - val <= 24*3600 and re.search(
						r'(?i)^[\d:]+\s*(am|pm)?\s*([-+][\d:]+|\w+|\w+[-+][\d:]+)?$', ts_str.strip() ):
					ts_list.append(ts)
					ts_ext.append('+ 1 day') # note: just val+=24*3600 can be incorrect due to DST
					continue
				ts = dt.datetime.fromtimestamp(val) # note: naive dt in local tz
				# Try to add +1 year to timestamps that don't
				#  have a YYYY spec and resolve to past dates
				if ( in_future and 0 < ts_now_sec - val <= 365*24*3600
						and ts.date() != ts_now_date and not re.search(r'\b\d{4}\b', ts_str) ):
					ts_list.append(ts)
					ts = ts.replace(year=ts.year+1)
			elif ',' in ts_str_ext:
				# "date -d" seem to have issues with commas, but removing them works
				ts_ext = list(str(v).replace(',', ' ') for v in ts_ext)
				continue
			break
		if multiple: ts = ts_list + [ts]
	if ts:
		if not isinstance(ts, list): ts = [ts]
		if tz: ts = list(tz.localize(ts, is_dst=None) for ts in ts)
		if not multiple: ts = ts[-1]
		return ts
	raise TSParseError(ts_str)

def parse_ts_interval(ts_str):
	# EVERY:
	#   "every" {
	#     [ ( NN[suffix][ "-" MM[suffix]] )+ | DELTA-DATE-SPEC ]
	#       [WD[-WD]]+
	#       ["at"] [TIME ["[" TZ "]"]]
	#     | DELTA-SPEC "interval" }
	#   suffix: st, nd, rd, th
	#   example: every 1st-11th at 5am UTC
	# DELTA-SPEC:
	#   ( N || unit )+
	#   units:
	#     y, yr, year, mo, month, w, week, d, day,
	#     h, hr, hour, m, min, minute, s, sec, second
	#   example: 3mo 1d 5hrs 10minutes 30s
	# DELTA-DATE-SPEC:
	#   subset of DELTA-SPEC wrt allowed units
	#   units: y, yr, year, mo, month, w, week, d, day
	# WD:
	#   monday mon, tuesday tu tue tues, wednesday wed,
	#   thursday th thu thur thurs, friday fri, saturday sat, sunday sun
	# TZ:
	#   ( "UTC" | ("+"|"-") HH:MM | region/place | abbrev )
	#   examples: +05:00, America/Los_Angeles, BST
	#     (anything that pytz can parse, basically)
	# TIME:
	#   ( [H]H[:MM[:SS]] ["am"|"pm"] | "noon" | "midnight" )

	# DELTA-SPEC "interval"
	m = re.search(r'(?i)^(.*)\binterval$', ts_str)
	if m: return parse_delta_spec(m.group(1).strip())

	# More conventional specification
	ts_str_base, dt_filter = ts_str, dict.fromkeys(IntervalFilter._fields)
	mo_days = dt_filter['mo_days'] = set()
	weekdays = dt_filter['weekdays'] = set()
	ts_str_re = r'(\s+(?P<rest>.*)|$)'

	# ( NN[suffix][ "-" MM[suffix]] )+
	while True:
		m = re.search( r'(?i)^(?P<a>\d+)(st|nd|rd|th)?'
			r'(\s*-\s*(?P<b>\d+)(st|nd|rd|th)?)?' + ts_str_re, ts_str )
		if not m: break
		a, b, ts_str = m.group('a'), m.group('b'), m.group('rest') or ''
		if b: mo_days.update(range(int(a), int(b)+1))
		else: mo_days.add(int(a))
	# DELTA-DATE-SPEC
	spec, delta, ts_str = ts_str.split(), None, list()
	while True:
		if not spec: break
		try: delta = parse_delta_spec(' '.join(spec))
		except TSParseError: pass
		else: break
		ts_str.append(spec.pop())
	if delta:
		if mo_days: raise TSParseError(' '.join(spec), mo_days, delta)
		if delta.h or delta.m or delta.s: raise TSParseError(' '.join(spec), delta)
		dt_filter['mo_days'] = delta
	ts_str = ' '.join(reversed(ts_str))
	# [WD[-WD]]+
	wd_re = re.compile( r'(?i)^(?P<a>{0})(\s*-\s*'
		r'(?P<b>{0}))?{1}'.format(_filter_weekdays_re, ts_str_re) )
	wd_match = lambda s: next( n for n, wd in
		enumerate(_filter_weekdays, 1) if s.startswith(wd[0]) )
	while True:
		m = wd_re.search(ts_str)
		if not m: break
		a, b, ts_str = m.group('a'), m.group('b'), m.group('rest') or ''
		if b: weekdays.update(range(wd_match(a.lower()), wd_match(b.lower())+1))
		else: weekdays.add(wd_match(a.lower()))
	# "at"
	m = re.search(r'(?i)^\s*at' + ts_str_re, ts_str)
	if m: ts_str = m.group('rest') or ''
	# TIME
	m = re.search(r'(?i)^(noon|midnight)\b' + ts_str_re, ts_str)
	if m:
		spec = m.group(1)
		ts_str = dict(noon='12:00', midnight='00:00')[spec]
		if m.group('rest'): ts_str += ' ' + m.group('rest')
	m = re.search( r'(?i)^(?P<h>\d{1,2})(:(?P<m>\d{2})'
		r'(:(?P<s>\d{2}))?)?(\s*(?P<x>am|pm))?' + ts_str_re, ts_str )
	if m:
		x, ts_str = m.group('x'), m.group('rest') or ''
		h, m, s = (int(m.group(k) or 0) for k in 'h m s'.split())
		if x and x.lower() == 'pm': h = h%12 + 12
		dt_filter['time'] = h, m, s
	# TZ
	m = re.search(r'^\[\s*(\S.*\S)\s*\]' + ts_str_re, ts_str)
	if m: dt_filter['tz'], ts_str = pytz.timezone(m.group(1).replace(' ', '_')), m.group('rest')
	# Leftovers
	if ts_str: raise TSParseError(ts_str)
	return IntervalFilter(**dt_filter)

def repr_ts(ts):
	if not ts: return str(ts)
	return conv_ts_local(ts)\
		.strftime('[%a %Y-%m-%d %H:%M:%S.%f %z]')

def repr_ts_diff( ts, ts0=None,
		ext=None, units_max=2, units_res=None,
		_units=dict( h=3600, m=60, s=1,
			y=365.25*86400, mo=30.5*86400, w=7*86400, d=1*86400 ) ):
	delta = abs(
		(ts - (ts0 or dt.datetime.now()))
		if not isinstance(ts, dt.timedelta) else ts )
	res, s, n_last = list(), delta.total_seconds(), units_max - 1
	for unit, unit_s in sorted(_units.items(), key=op.itemgetter(1), reverse=True):
		val = math.floor(s / unit_s)
		if not val:
			if units_res == unit: break
			continue
		if len(res) == n_last or units_res == unit:
			val, n_last = round(s / unit_s), True
		res.append('{:.0f}{}'.format(val, unit))
		if n_last is True: break
		s -= val * unit_s
	if not res: return '-'
	else:
		if ext: res.append(ext)
		return ' '.join(res)

def apply_ts_delta( ts, delta,
		ts_limit=conv_ts_utc(dt.datetime.now()) + dt.timedelta(365) ):
	if isinstance(delta, IntervalDelta):
		delta_has_time = False
		for offset in delta:
			if isinstance(offset, tuple):
				n, k = offset
				if n != 0:
					n = getattr(ts, k) + n
					if k == 'month' and n > 12:
						while n > 12: ts, n = ts.replace(year=ts.year+1), n - 12
						ts = ts.replace(month=n)
					else: ts = ts.replace(**{k: n})
			elif offset.total_seconds() != 0:
				ts += offset
				if offset.seconds: delta_has_time = True
		if not delta_has_time:
			ts = conv_ts_utc( conv_ts_local(ts)\
				.replace(hour=0, minute=0, second=0, microsecond=0) )
	elif isinstance(delta, IntervalFilter):
		ts0, ts_ref = ts, ts - delta_1d
		while True:
			if ts_ref > ts_limit: raise TSOverflow(ts_limit, delta)
			ts_ref += delta_1d
			if delta.tz: ts = delta.tz.localize(ts_ref.replace(tzinfo=None), is_dst=None)
			else: ts = conv_ts_local(ts_ref)
			if ( delta.mo_days
				and isinstance(delta.mo_days, set)
				and ts.day not in delta.mo_days ): continue
			if delta.weekdays and ts.isoweekday() not in delta.weekdays: continue
			ts = ts.replace( microsecond=0,
				**dict(zip('hour minute second'.split(), delta.time or (0, 0, 0))) )
			ts = conv_ts_utc(ts)
			if ts > ts0: break
	else: raise NotImplementedError(delta)
	return ts



### ReST parser

def parse_cal_list_from_rst(rst_str):
	from docutils import frontend as rst_front
	from docutils.parsers import rst
	import docutils.utils as rst_utils

	class RstLookupError(Exception): pass
	class RstLookupFound(Exception): pass

	def rst_lookup( root, tag,
			default=RstLookupError, recursive=False, one=True, text=True ):
		res, opts = list(), dict(one=one, recursive=recursive)
		tag = tag.split()
		if len(tag) > 1:
			opts_path = dict(opts.items(), text=False)
			for tag_path in tag[:-1]:
				if not root: break
				root = rst_lookup(root, tag_path, **opts_path)
			tag = tag[-1]
		else: tag = tag[0]
		if tag.endswith('...'): one, tag = False, tag[:-3]
		def collect(e):
			if one: raise RstLookupFound(e)
			if isinstance(e, list): res.extend(e)
			else: res.append(e)
		if not root: root = list()
		es = ( root.children if not isinstance(root, list)
			else it.chain.from_iterable(e.children for e in root) )
		try:
			for e in es:
				if e.tagname == tag: collect(e)
				if recursive:
					e = rst_lookup(e, tag, **opts)
					if e: collect(e)
		except RstLookupFound as res:
			res = res.args[0]
			return res if not text else res.astext()
		if one or not res:
			if default is not RstLookupError: return default
			raise RstLookupError(root, tag)
		if text: res = list(e.astext() for e in res)
		return res

	def rst_cal_info(root):
		try: fields = rst_lookup(root, 'field_list...', text=False)
		except RstLookupError: return
		res = dict()
		for e in rst_lookup(fields, 'field...', text=False):
			key = rst_lookup(e, 'field_name').replace('-', '_')
			res.setdefault(key, list()).append(rst_lookup(e, 'field_body paragraph'))
		if not (res.get('ts') or res.get('ts_start')): return
		ts_str_norm = lambda ts: ts.replace('_', ' ').strip()
		if res.get('ts'):
			ts_str_list, res['ts'] = res['ts'], list()
			res['raw_ts'] = ts_str_list
			for ts in ts_str_list:
				ts = ts_str_norm(ts)
				if not ts: continue
				res['ts'].extend(parse_ts_or_interval(ts, multiple=True))
		else: res['ts'] = res['raw_ts'] = list()
		for k in 'ts_start', 'ts_end', 'duration':
			k_raw = f'raw_{k}'
			if not res.get(k):
				res[k] = res[k_raw] = None
				continue
			assert len(res[k]) == 1, [k, res[k]]
			res[k_raw], res[k] = res[k], ( parse_ts
				if k != 'duration' else parse_duration )(ts_str_norm(res[k][0]))
		return res

	def rst_cal_list(root, depth=0, sections=None, cals=None):
		if cals is None: cals = list()
		if not sections: sections = list()
		for e in root.children:
			e_sec = None
			if e.tagname == 'section':
				e_sec = sections.copy() + [rst_lookup(e, 'title')]
			cal_info = rst_cal_info(e)
			if cal_info:
				if not cal_info.get('title'):
					cal_info['title'] = ( e_sec[-1]
						if e_sec else rst_lookup(e, 'paragraph') )
				cal_info['path'] = sections
				cals.append(cal_info)
			rst_cal_list(e, depth+1, e_sec or sections, cals)
		return cals

	settings = rst_front.OptionParser(components=(rst.Parser,)).get_default_values()
	rst_tree = rst_utils.new_document('cal_list', settings)
	rst.Parser().parse(rst_str, rst_tree)
	return rst_cal_list(rst_tree)



### Text-based output generators

EventInfo = cs.namedtuple('EventInfo', 'ts0 ts1 cal')

text_params_default = dict(
	max_text_lines=9, max_text_break='[more]', max_text_color='d9374c',
	eta_res='h', line_color='aaa', line_pos=-9, line_step=1, line_w=1,
	color='', c_weekday='lightgray', c_date='gray', c_time='lightgray', c_title='',
	c_eta_day='lightgray', c_eta_pass='999', c_eta_12='42a150', c_eta_6='9ebd5f',
	c_eta_4='d9d277', c_eta_3='f4ae58', c_eta_2='e87733', c_eta_1='d10027',
	pos_weekday=65, pos_date=0, pos_title=170,
	pos_time_fixed=110, pos_time_span=100, pos_time_from=100, pos_time_until=100 )

def text_params_str_parse(text_params_str, base=text_params_default):
	text_params = adict(base.copy())
	if not text_params_str: return text_params
	if not isinstance(text_params_str, str):
		text_params_str = ' '.join(text_params_str)
	for spec in it.chain.from_iterable(
			col.strip().split() for col in text_params_str.split(',') ):
		try:
			k, v = spec.split('=', 1)
			if k not in text_params: raise ValueError(k)
			text_params[k] = v
		except ValueError:
			parser.error(f'Invalid column/width spec: {spec!r}')
	return text_params

def text_event_time_repr(ts_now, day, ts0, ts1):
	'Return string repr for time within specified day, time/span type and delta until event.'
	tk = None
	if ts0 == ts1 or (ts1 - ts0).total_seconds() < 3*60:
		if not ts0.hour == ts0.minute == 0: tk = 'fixed'
	elif (ts0 - delta_1s).date() < day and (ts1 + delta_1s).date() > day: pass # whole day
	elif ts0.date() == day and ts1.date() == day: tk = 'span'
	elif (ts0 - delta_1s).date() == (ts0 + delta_1s).date() == day: tk = 'from'
	elif (ts1 - delta_1s).date() == (ts1 + delta_1s).date() == day: tk = 'until'

	ts = conv_ts_local(ts_now) # for correct ts.date()
	if tk == 'fixed':
		delta, day_ts = ts0 - ts, ts0.strftime('%H:%M')
	elif tk == 'span':
		day_ts = ts0.strftime('%H:%M') + '-' + ts1.strftime('%H:%M')
		delta = (ts1 - ts) if ts > ts1 else (
			(dt.timedelta(0) if ts > ts0 else (ts0 - ts)) )
	elif tk == 'from':
		day_ts = 'from ' + ts0.strftime('%H:%M')
		delta = dt.timedelta(0) if ts > ts0 else (ts0 - ts)
	elif tk == 'until':
		day_ts = 'until ' + ts1.strftime('%H:%M')
		delta = ( (ts1 - ts) if ts > ts1 else
			((ts0 - ts) if ts < ts0 else dt.timedelta(0)) )
	else:
		day_ts = None
		delta = ( dt.timedelta(0) if ts.date() == day
			else ((ts0 - ts) if ts < ts0 else (ts - ts1)) )

	return day_ts, tk, delta

def conky_eta_color(delta, cc):
	s = delta.total_seconds()
	if s < 0: return cc.c_eta_pass
	if s > 24 * 3600: return cc.c_eta_day
	k = None
	for n in range(24, 0, -1):
		k_new = f'c_eta_{n}'
		if k_new not in cc: continue
		if s <= n * 3600: k = k_new
		else: break
	return cc.get(k) or ''

def text_report_gen(dst, ts_now, day0, day1, events, text_params, conky=False):
	day, lines, delta_dedup = day0, 0, set()
	cc_base = cc = text_params
	cc.max_text_lines = int(cc.max_text_lines) - 1
	if not conky:
		plain_div, plain_strftime_len, plain_strftime = '- '*21, 16, ' %Y-%m-%d %a '
	while day < day1:
		day_events = list()
		for ts0, ts1, cal in events:
			if not ts0.date() <= day <= ts1.date(): continue
			day_ts, tk, delta = text_event_time_repr(ts_now, day, ts0, ts1)
			day_events.append((day_ts, tk, delta, cal))

		if day_events and lines <= cc.max_text_lines:
			day_start = True
			if lines:
				if not conky: dst.write(plain_div + '\n')
				else:
					dst.write(
						f'${{color {cc.line_color}}}${{voffset {cc.line_pos}}}'
						f'${{stippled_hr {cc.line_step} {cc.line_w}}}'
						f'${{voffset {-int(cc.line_pos)}}}${{color {cc.color}}}' )
			if not conky: dst.write(day.strftime(plain_strftime))
			else:
				dst.write(day.strftime(
					f'${{goto {cc.pos_weekday}}}${{color {cc.c_weekday}}}%a${{color}}'
					f'${{goto {cc.pos_date}}}${{color {cc.c_date}}}%Y-%m-%d${{color}}' ))

			for day_ts, tk, delta, cal in day_events:
				if lines > cc.max_text_lines: break
				if not conky and not day_start: dst.write(day.strftime(' '*plain_strftime_len))
				day_start, cc = False, text_params_str_parse(cal.get('conky'), cc_base)
				if not conky: dst.write(f'{day_ts or "":^14}')
				elif day_ts:
					pos = cc[f'pos_time_{tk}']
					dst.write( f'${{goto {pos}}}'
						f'${{color {cc.c_time}}}{day_ts}${{color {cc.color}}}' )
				delta_str = repr_ts_diff(
					delta, units_res=cc.eta_res,
					ext=None if delta.total_seconds() >= 0 else 'ago' )
				if not conky: title = f'[ {delta_str:>6} ]  {cal.title}'
				else:
					title = cal.title
					if title not in delta_dedup:
						delta_dedup.add(title)
						title += f'${{alignr}}${{color {conky_eta_color(delta, cc)}}}[ {delta_str} ]'
				if not conky: dst.write(title)
				else:
					dst.write( f'${{goto {cc.pos_title}}}'
						f'${{color {cc.c_title}}}{title}${{color {cc.color}}}' )
				if lines == cc.max_text_lines:
					if not conky: dst.write(f'\n{cc.max_text_break}')
					else:
						dst.write( f' ${{color {cc.max_text_color}}}'
							f'${{alignr}}{cc.max_text_break}${{color {cc.color}}}' )
				lines += 1
				dst.write('\n')

		day += delta_1d



### CLI

def main(args=None):
	text_params_default_str = ' '.join(f'{c}={o}' for c, o in text_params_default.items())

	import argparse, textwrap

	dedent = lambda text: (textwrap.dedent(text).strip('\n') + '\n').replace('\t', '  ')
	text_fill = lambda s,w=100,ind='\t',ind_next=None,**k: textwrap.fill(
		s, w, initial_indent=ind, subsequent_indent=ind if ind_next is None else ind_next, **k )
	class SmartHelpFormatter(argparse.HelpFormatter):
		def __init__(self, *args, **kws):
			return super().__init__(*args, **kws, width=100)
		def _fill_text(self, text, width, indent):
			if '\n' not in text: return super()._fill_text(text, width, indent)
			return ''.join( indent + line
				for line in text.replace('\t', '  ').splitlines(keepends=True) )
		def _split_lines(self, text, width):
			return super()._split_lines(text, width)\
				if '\n' not in text else dedent(text).splitlines()

	parser = argparse.ArgumentParser(
		formatter_class=SmartHelpFormatter,
		description='ReST-based calendar parser and online event tracker.')

	group = parser.add_argument_group('Input/output options')
	group.add_argument('rst_file', nargs='?',
		help='''
			ReST (.rst) file with calendar and event descriptions.
			Will be read from stdin, if "-" or not specified.''')
	group.add_argument('-i', '--ical', metavar='path',
		help='''
			Generate ICS (icalendar) output file at specified path.
			"-" can be unsed instead of path to output to stdout instead.''')
	group.add_argument('-p', '--plain', metavar='path',
		help='''
			Generate simple plaintext calendar, somewhat similar
				to conky config snippet, except without any conky-specific markup.
			 "-" can be unsed instead of path to output to stdout instead.''')
	group.add_argument('-c', '--conky', metavar='path',
		help='''
			Generate conky configuration snippet for e.g. execi or catp include/command.
			 "-" can be unsed instead of path to output to stdout instead.''')
	group.add_argument('-o', '--text-params',
		metavar='pos=offset,color=value,...', default=text_params_default_str,
		help='''
			Various text and conky config parameters in calendar table(s)
				generated by either -p/--plain or -c/--conky options.
			Overrides for one or more values can be specified in any order,
				separated by commas and/or spaces.
			For conky config, these can also be
				overidden on per-item basis via :conky: parameter in rst.
			Default parameters are:\n{}'''.format(
				text_fill(text_params_default_str, len(text_params_default_str) // 5 - 5, '\t'*4) ))

	group = parser.add_argument_group('Event filtering')
	group.add_argument('-e', '--event', metavar='title-part',
		help='Only match event(s) with specified part (case-insensitive) included in the title.')
	group.add_argument('-s', '--time-start', metavar='time', default='00:00',
		help='Time to use as a min cutoff point,'
			' i.e. disregard anything that is passed by it. Default: %(default)s')
	group.add_argument('-l', '--time-span', metavar='delta', default='1mo',
		help='Time delta from -s/--time-start to generate calendar entries for. Default: %(default)s')

	group = parser.add_argument_group('State tracking')
	group.add_argument('-d', '--state-file',
		metavar='path-tpl', default='/var/tmp/riet/src.{hash}.json',
		help='''
			Path or template for one, that will be used to store
					state for when "every X interval" entries were last displayed.
				"hash" component in the template will be replaced by hash of source rst path.
				Static path (no "{hash}" thing) must be specified to use with rst from stdin.
				Can be set to "-" to not track it and recalculate them from --time-start on each run.''')
	group.add_argument('-r', '--state-reset', metavar='title',
		help='Reset state for events with matching title'
				' (case-insensitive string-in-title match).'
			' Will raise error if no match was found.')
	group.add_argument('--state-flush',
		action='store_true', help='Discard any existing --state-file data.')
	group.add_argument('--state-preserve',
		action='store_true', help='Read/use, but do not update --state-file data.')

	group = parser.add_argument_group('Misc options')
	group.add_argument('-t', '--test-parse', metavar='( date/time | key=value )',
		help='''
			Test parsing specified date/time string, print resulting value and exit.
			Optionally, key=value entry can be specified, with one of the following
				keys (corresponding to ones in rst items): ts, ts-start, ts-end, duration.''')
	group.add_argument('--debug', action='store_true', help='Verbose operation mode.')

	opts = parser.parse_args(sys.argv[1:] if args is None else args)

	logging.basicConfig(
		format='%(levelname)s :: %(message)s',
		level=logging.DEBUG if opts.debug else logging.WARNING )

	if opts.test_parse:
		key, value = 'ts', opts.test_parse
		if '=' in value: key, value = value.split('=', 1)
		parser = dict( ts=parse_ts_or_interval, ts_start=parse_ts,
			ts_end=parse_ts, duration=parse_duration )[key.replace('-', '_').lower()]
		res = parser(value)
		res_str = ( repr_ts(res) if isinstance(res, dt.datetime)
			else str(res).replace('datetime.', '').replace('timedelta(', 'td(') )
		if len(res_str) > 50: res_str = '\n' + text_fill(res_str, len(res_str) / 2 + 5, ' '*2, ' '*4)
		print(f'Raw value: {value!r}')
		print(f'Parsed value (field={key}): {res_str}')
		if isinstance(res, dt.timedelta): print(f'Total seconds: {res.total_seconds()}')
		if isinstance(res, dt.datetime): print(f'POSIX timestamp: {res.timestamp()}')
		return

	rst_stdin, rst_path = not opts.rst_file or opts.rst_file == '-', pl.Path(opts.rst_file)
	with open(sys.stdin.fileno() if rst_stdin else rst_path) as src: rst_text = src.read()

	state_path, state = opts.state_file, PersistentState()
	if '{hash}' in state_path:
		if rst_stdin: state_path = '-'
		else: state_path = state_path.format(hash=str_hash(rst_path.resolve()))
	if state_path == '-': state_path = None
	if state_path:
		state_path = pl.Path(state_path).resolve()
		log.debug('Using state-file path: {}', state_path)
		state_path.parent.mkdir(parents=True, exist_ok=True, mode=0o700)
		if state_path.exists(): state.load(json.loads(state_path.read_text()))
	if opts.state_flush: state.clear()
	state_reset_found, state_reset = False, opts.state_reset and opts.state_reset.lower()

	if opts.ical:
		import icalendar as ic # https://tools.ietf.org/html/rfc5545
		ical, ev = ic.Calendar(), None
		ical.add('prodid', '-//rst-icalendar-event-tracker//fraggod.net//EN')
		ical.add('version', '2.0')
	if opts.conky or opts.plain:
		ev_list = list()
		text_params = text_params_str_parse(opts.text_params)

	ts_min = conv_ts_utc(parse_ts(opts.time_start, in_future=False))
	ts_max = ts_min + parse_duration(opts.time_span)
	cal_list = parse_cal_list_from_rst(rst_text.replace('\t', '  '))

	# Loop: cal_list (events) -> ts_list (ts0-ts1 pairs)
	for cal in map(adict, cal_list):
		if opts.event and opts.event.lower() not in cal.title.lower(): continue

		ts_list, ts0, ts1, ts_hashes = cal.ts, cal.ts_start, cal.ts_end, set()
		ts0, ts1 = map(conv_ts_utc, [ts0, ts1])
		if ts1 and ts1 < ts0: ts1 = ts1.replace(year=ts1.year + 1)
		if not ts_list: ts_list = [ts0]
		ts_base = ts0, ts1

		for n, ts in enumerate(ts_list):
			(ts0, ts1), ts_list[n] = ts_base, None
			if isinstance(ts, dt.datetime):
				if ts0 and ts1 and ts != ts0:
					log.warning( 'Ignoring fixed-time "ts" field for entry,'
						' as "ts-start"/"ts-end" are used instead: {!r} [{}]', cal.title, ts )
				elif not ts0: ts0 = conv_ts_utc(ts)
			else:
				ts0_k = tuple_hash((cal.title, ts0, ts))
				ts_hashes.add(ts0_k)
				if state_reset and state_reset in cal.title.lower():
					state_reset_found = True
					state.pop(ts0_k, None)
				ts0_orig = conv_ts_utc(state.get(ts0_k))
				ts0 = ts0_pre = ts0_orig or ts0 or ts_min
				if ts1 and ts0 > ts1: # event ending in the past
					ts0 = None
					break
				try:
					while ts0 <= ts_min:
						ts0_pre, ts0 = ts0, apply_ts_delta(ts0, ts, ts_max)
				except TSOverflow: # no events within timespan
					ts0 = None
					break
				if ts0_pre != ts0_orig: state[ts0_k] = ts0.timestamp()
				if isinstance(ts, IntervalFilter) and not ts.time: # day spans
					ts1 = ts0
					while True: # iterate until span ends
						try: ts1_next = apply_ts_delta(ts1, ts, ts_max)
						except TSOverflow: break
						if ts1_next != ts1 + delta_1d: break
						ts1 = ts1_next
					ts1 += delta_1d - delta_1s # extend until end of last day

			if not ts0: continue
			if not ts1:
				ts1 = ts0
				if cal.duration: ts1 += cal.duration
			if ts1 < ts_min or ts0 > ts_max: continue
			ts_list[n] = ts0, ts1

		ts_list = list(filter(None, ts_list))

		if log.isEnabledFor(logging.DEBUG):
			log.debug('')
			log.debug('----- title: {}', cal.title)
			log.debug('  raw: ts={} start={} end={}', cal.raw_ts, cal.raw_ts_start, cal.raw_ts_end)
			if ts_hashes: log.debug('  hashes: {}', ' '.join(sorted(ts_hashes)))
			for ts0, ts1 in ts_list:
				log.debug('  result [{}]:', repr_ts_diff(ts1 - ts0))
				log.debug('    from: {}', repr_ts(ts0))
				log.debug('    to:   {}', repr_ts(ts1))
			urls = cal.get('url', list()) + cal.get('feed_rss', list())
			for url in urls: log.debug('  url: {}', url)

		for ts0, ts1 in ts_list:
			if opts.ical:
				ev = ic.Event()
				ev.add('summary', cal.title)
				ev.add('dtstart', conv_ts_local(ts0))
				ev.add('dtend', conv_ts_local(ts1))
				ev.add('dtstamp', conv_ts_local(ts_min))
				if cal.get('url'): ev.add('url', cal.url)
				ical.add_component(ev)
			if opts.conky or opts.plain:
				ev_list.append(EventInfo(
					conv_ts_local(ts0), conv_ts_local(ts1), cal ))

	if state_reset and not state_reset_found:
		print( 'ERROR: Failed to find event title'
			f' matching --state-reset option: {state_reset}', file=sys.stderr )
		return 1

	if opts.ical:
		if ev:
			path = str(pl.Path(opts.ical).expanduser())
			log.debug('Generating resulting ICS file: {}', path)
			dst_stream = ( open(sys.stdout.fileno(), 'wb')
				if path == '-' else safe_replacement(path, 'wb') )
			with dst_stream as dst: dst.write(ical.to_ical())
		else: log.debug('No calendar entries within timespan, skipping ICS generation')

	if opts.conky or opts.plain:
		ev_list.sort(key=op.attrgetter('ts0'))
		ts_now = dt.datetime.utcnow().replace(tzinfo=pytz.utc)
		day0, day1 = conv_ts_local(ts_min).date(), conv_ts_local(ts_max).date()
		for report_type in 'conky', 'plain':
			path = getattr(opts, report_type)
			if not path: continue
			path = str(pl.Path(path).expanduser())
			log.debug('Generating {} configuration snippet: {}', report_type, path)
			dst_stream = ( open(sys.stdout.fileno(), 'w')
				if path == '-' else safe_replacement(path) )
			with dst_stream as dst:
				text_report_gen(
					dst, ts_now, day0, day1, ev_list,
					text_params, conky=report_type == 'conky' )

	if state_path and not opts.state_preserve and state.data:
		state.cleanup(timeout=2*365*24*3600)
		with safe_replacement(state_path) as dst: json.dump(state.dump(), dst)

if __name__ == '__main__': sys.exit(main())
